{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Categorisation - TensorFlow - MLE\n",
    "\n",
    "This time we use GCP Cloud ML Engine (MLE) to:\n",
    "\n",
    "- Accelerate training\n",
    "- Deploy the model to an production endpoint \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "Lets configure the project parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'irisml-217400' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'iris-demo-4a8337d54c6d59x9' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'asia-east1'  # Closet region with MLE (can't train on asia-northeast1)\n",
    "ENDPOINT_REGION = 'asia-northeast1' \n",
    "\n",
    "# For Python Code\n",
    "# Model Info\n",
    "MODEL_NAME = 'iris'\n",
    "# Model Version\n",
    "MODEL_VERSION = 'v1'\n",
    "# Training Directory name\n",
    "TRAINING_DIR = 'iris_trained'\n",
    "TFVERSION = '1.10'\n",
    "\n",
    "# For Bash Code (because google-cloud-storage is lousy)\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['ENDPOINT_REGION'] = ENDPOINT_REGION\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['MODEL_VERSION'] = MODEL_VERSION\n",
    "os.environ['TRAINING_DIR'] = TRAINING_DIR \n",
    "os.environ['TFVERSION'] = TFVERSION  # Tensorflow version\n",
    "os.environ['OUTDIR'] = 'gs://{BUCKET}/trained'.format(BUCKET=BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project ${PROJECT}\n",
    "gcloud config set compute/region ${REGION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our Bucket and Configure Access\n",
    "\n",
    "No need to download the data locally again if you have it already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First get the service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "\n",
    "ml = discovery.build('ml', 'v1', credentials=credentials,\n",
    "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "# I find it baffling why the `.projects()` method is used instead of `.Project('project-name').get_config()`\n",
    "project_config = ml.projects().getConfig(name='projects/'+ PROJECT).execute()\n",
    "os.environ['SVC_ACCOUNT'] = project_config[u'serviceAccount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://iris-demo-4a8337d54c6d59x9/...\n",
      "ServiceException: 409 Bucket iris-demo-4a8337d54c6d59x9 already exists.\n",
      "No changes to gs://iris-demo-4a8337d54c6d59x9/\n",
      "Copying file://../data/iris_test.csv [Content-Type=text/csv]...\n",
      "Copying file://../data/iris_training.csv [Content-Type=text/csv]...\n",
      "/ [0 files][    0.0 B/  573.0 B]                                                \r",
      "/ [0/3 files][    0.0 B/  1.0 MiB]   0% Done                                    \r",
      "Copying file://../data/validation_data.hdf [Content-Type=application/x-hdf]...\n",
      "/ [0/3 files][    0.0 B/  1.0 MiB]   0% Done                                    \r",
      "/ [1/3 files][  1.0 MiB/  1.0 MiB]  99% Done                                    \r",
      "/ [2/3 files][  1.0 MiB/  1.0 MiB]  99% Done                                    \r",
      "/ [3/3 files][  1.0 MiB/  1.0 MiB] 100% Done                                    \r\n",
      "Operation completed over 3 objects/1.0 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil mb -p ${PROJECT} -l ${REGION} gs://${BUCKET}\n",
    "gsutil -m acl ch -u ${SVC_ACCOUNT}:W gs://${BUCKET} \n",
    "gsutil -m cp -r ../data gs://${BUCKET}                  # Send test and training data to GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://iris-demo-4a8337d54c6d59x9/data/iris_test.csv\n",
      "gs://iris-demo-4a8337d54c6d59x9/data/iris_training.csv\n",
      "gs://iris-demo-4a8337d54c6d59x9/data/validation_data.hdf\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Package\n",
    "\n",
    "ML Engine requires that we give it an installable python package.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  model.py  task.py\r\n"
     ]
    }
   ],
   "source": [
    "ls ../package/trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally before Sending to MLE\n",
    "\n",
    "The model gets the data from Cloud Storage, so to test locally we need to install the python package to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-storage\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/62/a2e3111bf4d1eb54fe86dec694418644e024eb059bf1e66ebdcf9f98ad70/google_cloud_storage-1.13.0-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 16.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-api-core<2.0.0dev,>=0.1.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-storage) (0.1.4)\n",
      "Requirement already satisfied: google-cloud-core<0.29dev,>=0.28.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-storage) (0.28.1)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-storage) (0.3.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (2.18.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.5.3 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (1.5.3)\n",
      "Requirement already satisfied: pytz in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (2016.7)\n",
      "Requirement already satisfied: futures>=3.2.0; python_version < \"3.2\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (3.2.0)\n",
      "Requirement already satisfied: google-auth<2.0.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (1.5.1)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (3.5.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (1.10.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (40.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (2018.8.13)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (0.2.2)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (2.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (3.4.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0.0dev,>=0.4.0->google-api-core<2.0.0dev,>=0.1.1->google-cloud-storage) (0.4.4)\n",
      "Installing collected packages: google-cloud-storage\n",
      "Successfully installed google-cloud-storage-1.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Tensorflow version: 1.8.0\n",
      "Received OUTDIR: /tmp/trained\n",
      "Downloading: gs://iris-demo-4a8337d54c6d59x9/data/iris_training.csv\n",
      "Downloading: gs://iris-demo-4a8337d54c6d59x9/data/iris_test.csv\n",
      "Defining training spec\n",
      "Expecting data from:  /tmp/data/iris_training.csv\n",
      "Defining eval spec\n",
      "Expecting data from:  /tmp/data/iris_test.csv\n",
      "Starting training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {}, u'job': {u'args': [u'--outdir=/tmp/trained', u'--train_steps=2', u'--bucket=iris-demo-4a8337d54c6d59x9', u'--project=irisml-217400', u'--test_file=data/iris_test.csv', u'--train_file=data/iris_training.csv'], u'job_name': u'trainer.task'}, u'task': {}}\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdbef8edb50>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/trained', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 1 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-10-10 09:30:01.436538: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 285.80945, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into /tmp/trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 106.48973.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-10-09:30:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/trained/model.ckpt-2\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-10-09:30:02\n",
      "INFO:tensorflow:Saving dict for global step 2: accuracy = 0.26666668, average_loss = 1.0816562, global_step = 2, loss = 32.449688\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'SepalLength': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'PetalLength': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'PetalWidth': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'SepalWidth': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'SepalLength': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'PetalLength': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'PetalWidth': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'SepalWidth': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /tmp/trained/model.ckpt-2\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /tmp/trained/export/exporter/temp-1539163802/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use Cloud Machine Learning Engine to train the model in local file system\n",
    "# same as:\n",
    "# python package/trainer/task.py\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=${PWD}/../package/trainer \\\n",
    "    -- \\\n",
    "    --outdir=/tmp/trained \\\n",
    "    --train_steps=2 \\\n",
    "    --bucket=${BUCKET} \\\n",
    "    --project=${PROJECT}  \\\n",
    "    --test_file=data/iris_test.csv  \\\n",
    "    --train_file=data/iris_training.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Ensure our exported model is service predictions properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /usr/local/envs/py2env/lib/python2.7/site-packages (3.4.4)\r\n",
      "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tables) (2.6.8)\r\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tables) (1.14.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tables) (1.10.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIES = {0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_hdf('../data/validation_data.hdf', 'test1')\n",
    "\n",
    "features = valid.drop('Species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected class outputs are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Expected class outputs are: ')\n",
    "valid['Species'].map({v:k for k,v in SPECIES.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_json('../test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"PetalLength\":1.7,\"PetalWidth\":0.5,\"SepalLength\":5.1,\"SepalWidth\":3.3}\r\n",
      "{\"PetalLength\":4.2,\"PetalWidth\":1.5,\"SepalLength\":5.9,\"SepalWidth\":3.0}\r\n",
      "{\"PetalLength\":5.4,\"PetalWidth\":2.1,\"SepalLength\":6.9,\"SepalWidth\":3.1}"
     ]
    }
   ],
   "source": [
    "!cat '../test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_IDS  CLASSES  LOGITS                                                           PROBABILITIES\n",
      "[2]        [u'2']   [-0.3140818476676941, 0.18077421188354492, 0.41236674785614014]  [0.2124050408601761, 0.34839996695518494, 0.43919506669044495]\n",
      "[2]        [u'2']   [-0.8448461890220642, 0.20084339380264282, 0.9563210606575012]   [0.1009889617562294, 0.2873499393463135, 0.6116611361503601]\n",
      "[2]        [u'2']   [-1.127501130104065, 0.16294443607330322, 1.3556257486343384]    [0.06019357964396477, 0.21876788139343262, 0.7210385203361511]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-10-10 09:30:09.742255: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# This model dir is the model exported after training and is used for prediction\n",
    "#\n",
    "MODEL_RESULTS=/tmp/trained\n",
    "latest_model_dir=$(ls ${MODEL_RESULTS}/export/exporter | tail -1)\n",
    "# predict using the trained model\n",
    "gcloud ml-engine local predict  \\\n",
    "    --model-dir=${MODEL_RESULTS}/export/exporter/${latest_model_dir} \\\n",
    "    --json-instances=../test.json #| awk {'print $1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on MLE\n",
    "\n",
    "Use cloud resources to train the model much more thouroughly than we can locally by increasing the training steps and the target machine (`--scale-tier`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://iris-demo-4a8337d54c6d59x9/trained asia-east1 iris_181010_093010\n",
      "jobId: iris_181010_093010\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/eval/#1538290082752480...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/checkpoint#1538290080288845...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/#1538290078949940...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/eval/events.out.tfevents.1538290082.cmle-training-2845701797023043042#1538290083694278...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/events.out.tfevents.1538290070.cmle-training-2845701797023043042#1538290089076800...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/export/#1538290084472278...\n",
      "/ [1/19 objects]   5% Done                                                      \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/export/exporter/#1538290084639511...\n",
      "/ [2/19 objects]  10% Done                                                      \r",
      "/ [3/19 objects]  15% Done                                                      \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/export/exporter/1538290083/#1538290088020745...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/export/exporter/1538290083/saved_model.pb#1538290088200501...\n",
      "/ [4/19 objects]  21% Done                                                      \r",
      "/ [5/19 objects]  26% Done                                                      \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/export/exporter/1538290083/variables/#1538290088358837...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/export/exporter/1538290083/variables/variables.data-00000-of-00001#1538290088533052...\n",
      "/ [6/19 objects]  31% Done                                                      \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/export/exporter/1538290083/variables/variables.index#1538290088753342...\n",
      "/ [7/19 objects]  36% Done                                                      \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/graph.pbtxt#1538290072013175...\n",
      "/ [8/19 objects]  42% Done                                                      \r",
      "/ [9/19 objects]  47% Done                                                      \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/model.ckpt-0.data-00000-of-00001#1538290073881238...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/model.ckpt-0.index#1538290074107167...\n",
      "/ [10/19 objects]  52% Done                                                     \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/model.ckpt-0.meta#1538290075364875...\n",
      "/ [11/19 objects]  57% Done                                                     \r",
      "/ [12/19 objects]  63% Done                                                     \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/model.ckpt-600.data-00000-of-00001#1538290079458502...\n",
      "/ [13/19 objects]  68% Done                                                     \r",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/model.ckpt-600.index#1538290079714151...\n",
      "Removing gs://iris-demo-4a8337d54c6d59x9/trained/model.ckpt-600.meta#1538290080945462...\n",
      "/ [14/19 objects]  73% Done                                                     \r",
      "/ [15/19 objects]  78% Done                                                     \r",
      "/ [16/19 objects]  84% Done                                                     \r",
      "/ [17/19 objects]  89% Done                                                     \r",
      "/ [18/19 objects]  94% Done                                                     \r",
      "/ [19/19 objects] 100% Done                                                     \r\n",
      "Operation completed over 19 objects.                                             \n",
      "Job [iris_181010_093010] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe iris_181010_093010\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs iris_181010_093010\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "JOBNAME=${MODEL_NAME}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "# Clear the Cloud Storage Bucket used for the training job\n",
    "gsutil -m rm -rf ${OUTDIR}\n",
    "gcloud ml-engine jobs submit training ${JOBNAME} \\\n",
    "   --region=${REGION} \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/../package/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://${BUCKET} \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --runtime-version=${TFVERSION} \\\n",
    "   -- \\\n",
    "    --outdir=${OUTDIR} \\\n",
    "    --train_steps=1000 \\\n",
    "    --bucket=${BUCKET} \\\n",
    "    --project=${PROJECT}  \\\n",
    "    --test_file=data/iris_test.csv  \\\n",
    "    --train_file=data/iris_training.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_LOCATION = gs://iris-demo-4a8337d54c6d59x9/trained/export/exporter/1539163961/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.models.create) Resource in project [irisml-217400] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "Creating version (this might take a few minutes)......\n",
      ".................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Create model\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions ${ENDPOINT_REGION}\n",
    "\n",
    "MODEL_LOCATION=$(gsutil ls ${OUTDIR}/export/exporter | tail -1)\n",
    "\n",
    "echo \"MODEL_LOCATION = ${MODEL_LOCATION}\"\n",
    "\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} \\\n",
    "    --model ${MODEL_NAME} --origin ${MODEL_LOCATION} \\\n",
    "    --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test new REST Endpoint\n",
    "\n",
    "Docs [here](https://cloud.google.com/ml-engine/reference/rest/v1/projects/predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [{\"probabilities\": [0.9957330822944641, 0.0042669884860515594, 6.210235505097611e-15], \"class_ids\": [0], \"classes\": [\"0\"], \"logits\": [12.176715850830078, 6.72414493560791, -20.531585693359375]}]}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100    87    0     0  100    87      0     59  0:00:01  0:00:01 --:--:--    59\r",
      "100   298    0   211  100    87     95     39  0:00:02  0:00:02 --:--:--    95\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "TEST_INSTANCE=\"{\\\"instances\\\":[$(cat ../test.json|head -1)]}\"\n",
    "\n",
    "curl -X POST -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    --data $TEST_INSTANCE \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}/models/iris:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "\n",
    "Remove the endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This will delete version [v1]...\n",
      "\n",
      "Do you want to continue (Y/n)?  Please enter 'y' or 'n':  \n",
      "Deleting version [v1]......\n",
      "........................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME} \n",
    "gcloud ml-engine models delete ${MODEL_NAME} -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
